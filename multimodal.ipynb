{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\admin\\desktop\\building multimodal search and rag\\env1\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\admin\\desktop\\building multimodal search and rag\\env1\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\admin\\desktop\\building multimodal search and rag\\env1\\lib\\site-packages (from scikit-learn) (1.13.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\admin\\desktop\\building multimodal search and rag\\env1\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\admin\\desktop\\building multimodal search and rag\\env1\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: umap-learn in c:\\users\\admin\\desktop\\building multimodal search and rag\\env1\\lib\\site-packages (0.5.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\admin\\desktop\\building multimodal search and rag\\env1\\lib\\site-packages (from umap-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.3.1 in c:\\users\\admin\\desktop\\building multimodal search and rag\\env1\\lib\\site-packages (from umap-learn) (1.13.0)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in c:\\users\\admin\\desktop\\building multimodal search and rag\\env1\\lib\\site-packages (from umap-learn) (1.4.2)\n",
      "Requirement already satisfied: numba>=0.51.2 in c:\\users\\admin\\desktop\\building multimodal search and rag\\env1\\lib\\site-packages (from umap-learn) (0.59.1)\n",
      "Requirement already satisfied: pynndescent>=0.5 in c:\\users\\admin\\desktop\\building multimodal search and rag\\env1\\lib\\site-packages (from umap-learn) (0.5.12)\n",
      "Requirement already satisfied: tqdm in c:\\users\\admin\\desktop\\building multimodal search and rag\\env1\\lib\\site-packages (from umap-learn) (4.66.4)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in c:\\users\\admin\\desktop\\building multimodal search and rag\\env1\\lib\\site-packages (from numba>=0.51.2->umap-learn) (0.42.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\admin\\desktop\\building multimodal search and rag\\env1\\lib\\site-packages (from pynndescent>=0.5->umap-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\admin\\desktop\\building multimodal search and rag\\env1\\lib\\site-packages (from scikit-learn>=0.22->umap-learn) (3.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\desktop\\building multimodal search and rag\\env1\\lib\\site-packages (from tqdm->umap-learn) (0.4.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\admin\\desktop\\building multimodal search and rag\\env1\\lib\\site-packages (4.66.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\desktop\\building multimodal search and rag\\env1\\lib\\site-packages (from tqdm) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install -q accelerate torch\n",
    "!pip install -U scikit-learn\n",
    "!pip install umap-learn\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "# Import basic computation libraries along with data visualization and plotting libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "import umap\n",
    "import umap.plot\n",
    "import plotly.graph_objs as go\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'iframe'\n",
    "\n",
    "# Import our data class which will organize MNIST and provide anchor, positive and negative samples.\n",
    "from mnist_dataset import MNISTDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 538/538 [00:01<00:00, 519.37it/s]\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 627.85it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load data from csv\n",
    "data = pd.read_csv('digit-recognizer/train.csv')\n",
    "val_count = 1000\n",
    "# common transformation for both val and train\n",
    "default_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(0.5, 0.5)\n",
    "])\n",
    "\n",
    "# Split data into val and train\n",
    "dataset = MNISTDataset(data.iloc[:-val_count], default_transform)\n",
    "val_dataset = MNISTDataset(data.iloc[-val_count:], default_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP DATALOADERS\n",
    "trainLoader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=16, # feel free to modify this value\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    num_workers=2,\n",
    "    prefetch_factor=100\n",
    ")\n",
    "\n",
    "valLoader = DataLoader(val_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    num_workers=2,\n",
    "    prefetch_factor=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x300 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x300 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_images(images, title=''):\n",
    "    num_images = len(images)\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(9, 3))\n",
    "    for i in range(num_images):\n",
    "        img = np.squeeze(images[i])\n",
    "        axes[i].imshow(img, cmap='gray')\n",
    "        axes[i].axis('off')\n",
    "    fig.suptitle(title)\n",
    "    plt.show()\n",
    "\n",
    "# Visualize some examples\n",
    "for batch_idx, (anchor_images, contrastive_images, distances, labels) in enumerate(trainLoader):\n",
    "    # Convert tensors to numpy arrays\n",
    "    anchor_images = anchor_images.numpy()\n",
    "    contrastive_images = contrastive_images.numpy()\n",
    "    labels = labels.numpy()\n",
    "    \n",
    "    # Display some samples from the batch\n",
    "    show_images(anchor_images[:4], title='Anchor Image')\n",
    "    show_images(contrastive_images[:4], title='+/- Example')\n",
    "    \n",
    "    # Break after displaying one batch for demonstration\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 5),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d((2, 2), stride=2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 5),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d((2, 2), stride=2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.linear1 = nn.Sequential(\n",
    "            nn.Linear(64 * 4 * 4, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 64),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x) # x: d * 32 * 12 * 12\n",
    "        x = self.conv2(x) # x: d * 64 * 4  * 4 \n",
    "        x = x.view(x.size(0), -1) # x: d * (64*4*4)\n",
    "        x = self.linear1(x) # x: d * 64\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The ideal distance metric for a positive sample is set to 1, for a negative sample it is set to 0      \n",
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.similarity = nn.CosineSimilarity(dim=-1, eps=1e-7)\n",
    "\n",
    "    def forward(self, anchor, contrastive, distance):\n",
    "        # use cosine similarity from torch to get score\n",
    "        score = self.similarity(anchor, contrastive)\n",
    "        # after cosine apply MSE between distance and score\n",
    "        return nn.MSELoss()(score, distance) #Ensures that the calculated score is close to the ideal distance (1 or 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Network()\n",
    "\n",
    "device = 'cuda'\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(device=device)\n",
    "    \n",
    "net = net.to(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training configuration\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.005)\n",
    "loss_function = ContrastiveLoss()\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define a directory to save the checkpoints\n",
    "checkpoint_dir = 'checkpoints/'\n",
    "\n",
    "# Ensure the directory exists\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epoch_count=10):#\n",
    "    net = Network()\n",
    "    lrs = []\n",
    "    losses = []\n",
    "\n",
    "    for epoch in range(epoch_count):\n",
    "        epoch_loss = 0\n",
    "        batches=0\n",
    "        print('epoch -', epoch)\n",
    "        lrs.append(optimizer.param_groups[0]['lr'])\n",
    "        print('learning rate', lrs[-1])\n",
    "    \n",
    "        for anchor, contrastive, distance, label in tqdm(trainLoader):\n",
    "            batches += 1\n",
    "            optimizer.zero_grad()\n",
    "            anchor_out = net(anchor.to(device))\n",
    "            contrastive_out = net(contrastive.to(device))\n",
    "            distance = distance.to(torch.float32).to(device)\n",
    "            loss = loss_function(anchor_out, contrastive_out, distance)\n",
    "            epoch_loss += loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        losses.append(epoch_loss.cpu().detach().numpy() / batches)\n",
    "        scheduler.step()\n",
    "        print('epoch_loss', losses[-1])\n",
    "    \n",
    "        # Save a checkpoint of the model\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f'model_epoch_{epoch}.pt')\n",
    "        torch.save(net.state_dict(), checkpoint_path)\n",
    "\n",
    "    return {\n",
    "        \"net\": net,\n",
    "        \"losses\": losses\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 0\n",
      "learning rate 0.005\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[47], line 13\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(epoch_count)\u001b[0m\n\u001b[0;32m     10\u001b[0m lrs\u001b[38;5;241m.\u001b[39mappend(optimizer\u001b[38;5;241m.\u001b[39mparam_groups[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning rate\u001b[39m\u001b[38;5;124m'\u001b[39m, lrs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m anchor, contrastive, distance, label \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainLoader\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     14\u001b[0m     batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     15\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\Users\\Admin\\Desktop\\Building Multimodal Search and RAG\\env1\\Lib\\site-packages\\tqdm\\notebook.py:234\u001b[0m, in \u001b[0;36mtqdm_notebook.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    232\u001b[0m unit_scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munit_scale \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munit_scale \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    233\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;241m*\u001b[39m unit_scale \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal\n\u001b[1;32m--> 234\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_printer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mncols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer\u001b[38;5;241m.\u001b[39mpbar \u001b[38;5;241m=\u001b[39m proxy(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\Desktop\\Building Multimodal Search and RAG\\env1\\Lib\\site-packages\\tqdm\\notebook.py:108\u001b[0m, in \u001b[0;36mtqdm_notebook.status_printer\u001b[1;34m(_, total, desc, ncols)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# Fallback to text bar if there's no total\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# DEPRECATED: replaced with an 'info' style bar\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# if not total:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    105\u001b[0m \n\u001b[0;32m    106\u001b[0m \u001b[38;5;66;03m# Prepare IPython progress bar\u001b[39;00m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m IProgress \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# #187 #451 #558 #872\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(WARN_NOIPYW)\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m total:\n\u001b[0;32m    110\u001b[0m     pbar \u001b[38;5;241m=\u001b[39m IProgress(\u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39mtotal)\n",
      "\u001b[1;31mImportError\u001b[0m: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html"
     ]
    }
   ],
   "source": [
    "\n",
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_from_checkpoint():\n",
    "    \n",
    "    checkpoint = torch.load('checkpoints/')\n",
    "    \n",
    "    net = Network()\n",
    "    net.load_state_dict(checkpoint)\n",
    "\n",
    "    net.eval()\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'checkpoints/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m     model \u001b[38;5;241m=\u001b[39m training_result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnet\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m----> 7\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[33], line 3\u001b[0m, in \u001b[0;36mload_model_from_checkpoint\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model_from_checkpoint\u001b[39m():\n\u001b[1;32m----> 3\u001b[0m     checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcheckpoints/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     net \u001b[38;5;241m=\u001b[39m Network()\n\u001b[0;32m      6\u001b[0m     net\u001b[38;5;241m.\u001b[39mload_state_dict(checkpoint)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\Desktop\\Building Multimodal Search and RAG\\env1\\Lib\\site-packages\\torch\\serialization.py:997\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m    994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    995\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 997\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m    998\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m    999\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m   1000\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m   1001\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m   1002\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32mc:\\Users\\Admin\\Desktop\\Building Multimodal Search and RAG\\env1\\Lib\\site-packages\\torch\\serialization.py:444\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    443\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 444\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    446\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32mc:\\Users\\Admin\\Desktop\\Building Multimodal Search and RAG\\env1\\Lib\\site-packages\\torch\\serialization.py:425\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 425\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'checkpoints/'"
     ]
    }
   ],
   "source": [
    "train = False # set to True to run train the model\n",
    "\n",
    "if train:\n",
    "    training_result = train_model()\n",
    "    model = training_result[\"net\"]\n",
    "else:\n",
    "    model = load_model_from_checkpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
